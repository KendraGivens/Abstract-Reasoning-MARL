{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24390d31-a22f-4132-bf14-f8e97f445816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 11:49:25.919327: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-25 11:49:25.919378: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-25 11:49:25.919409: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from enum import Enum, auto\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d96c93ab-e6ab-4295-9ee8-d51503fc7df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get config of qmix algorithim \n",
    "with open('qmix.yaml', 'r') as f:\n",
    "    qmix_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "# get config of environment\n",
    "with open('env.yaml', 'r') as f:\n",
    "    env_config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af6faad3-e235-43ea-a349-95babc583c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(Enum):\n",
    "    NO_OP = 0\n",
    "    MOVE_UP = auto()\n",
    "    MOVE_DOWN = auto()\n",
    "    MOVE_LEFT = auto()\n",
    "    MOVE_RIGHT = auto()\n",
    "    \n",
    "    @property\n",
    "    def delta(self):\n",
    "        if self == self.NO_OP:\n",
    "            return (0, 0)\n",
    "        if self == self.MOVE_UP:\n",
    "            return (-1, 0)\n",
    "        if self == self.MOVE_DOWN:\n",
    "            return (1, 0)\n",
    "        if self == self.MOVE_LEFT:\n",
    "            return (0, -1)\n",
    "        if self == self.MOVE_RIGHT:\n",
    "            return (0, 1)\n",
    "\n",
    "    @property \n",
    "    def shape(self):\n",
    "        return len(Actions)\n",
    "\n",
    "    @property \n",
    "    def one_hot(self):\n",
    "        return tf.one_hot(self.value, len(Actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed3dfb32-e203-415f-928b-655d6b92049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridEnv():\n",
    "    def __init__(self, rows, cols, num_agents):\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        \n",
    "        self.num_agents = num_agents\n",
    "        self.agent_list = []\n",
    "        \n",
    "        self.goal = []\n",
    "        self.block = []\n",
    "\n",
    "    def qmix(self):\n",
    "        agent_inputs = [agent.local_model.inputs for agent in self.agent_list]\n",
    "        agent_outputs = [agent.local_model.output for agent in self.agent_list]\n",
    "        global_state = tf.keras.layers.Input(batch_shape=(1, *np.shape(self.get_global_state())))\n",
    "\n",
    "        q_values = tf.keras.layers.Concatenate()(agent_outputs)\n",
    "        y = MixingLayer(grid)((q_values, global_state))\n",
    "        qmix = tf.keras.Model((agent_inputs, global_state), (agent_outputs, y))\n",
    "        qmix.compile(run_eagerly=True)\n",
    "        \n",
    "        return qmix\n",
    "\n",
    "    def populate_grid(self):\n",
    "        positions = np.random.choice(self.rows*self.cols, self.num_agents+2, replace=False)\n",
    "\n",
    "        self.goal = (positions[0]//self.cols, positions[0]%self.cols)\n",
    "        self.block = (positions[1]//self.cols, positions[1]%self.cols)\n",
    "\n",
    "        for i in range(self.num_agents):\n",
    "            agent = Agent(self, i)\n",
    "            agent.position = (positions[i+2]//self.cols, positions[i+2]%self.cols)\n",
    "            self.agent_list.append(agent)\n",
    "\n",
    "    def get_global_state(self):\n",
    "        return tf.one_hot([p[0]*self.cols+p[1] for p in (self.goal, self.block, *[a.position for a in self.agent_list])], self.rows*self.cols)\n",
    "    \n",
    "    def vizualize_grid(self): \n",
    "        grid = [list(\".\"*self.cols) for _ in range(self.rows)]\n",
    "\n",
    "        grid[self.goal[0]][self.goal[1]] = \"G\"\n",
    "        grid[self.block[0]][self.block[1]]= \"B\"\n",
    "\n",
    "        for i, agent in enumerate(self.agent_list):\n",
    "            grid[agent.position[0]][agent.position[1]] = str(i)\n",
    "\n",
    "        return '\\n'.join([' '.join(row) for row in grid])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.vizualize_grid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a354d3ab-cc86-44ca-a898-d4fc27f56f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, grid, id):\n",
    "        self.grid = grid\n",
    "\n",
    "        self.id = id\n",
    "        self.position = [0, 0]\n",
    "        self.epsilon = 0.1\n",
    "        self.gamma = 0.1\n",
    "        self.alpha = 0.1\n",
    "        \n",
    "        self.local_model = self._build_local_model() \n",
    "\n",
    "        self.history = ([], [])\n",
    "        self.previous_action = Actions.NO_OP\n",
    "\n",
    "    def get_local_state(self):\n",
    "        return self.grid.get_global_state()\n",
    "\n",
    "    def take_action(self, action):\n",
    "        future_position = self.position\n",
    "        future_position += np.array(action.delta)\n",
    "        future_position %= [self.grid.rows, self.grid.cols]\n",
    "\n",
    "        if list(future_position) not in [a.position for a in self.grid.agent_list]:\n",
    "            if list(future_position) == self.grid.block:\n",
    "                self.grid.block += np.array(action.delta)\n",
    "                self.grid.block %= [self.grid.rows, self.grid.cols]\n",
    "            else:\n",
    "                self.position = future_position\n",
    "            \n",
    "    def get_reward(self):\n",
    "        if self.grid.block == self.grid.goal:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def get_correct_qvalue(self, pred_max_value, reward, current_max_value):\n",
    "        q_value = pred_max_value + self.alpha * (reward + self.gamma * current_max_value - pred_max_value)\n",
    "        return q_value\n",
    "        \n",
    "    def _build_local_model(self):\n",
    "        local_state = tf.keras.layers.Input(batch_shape=(1, None, self.grid.num_agents+2, self.grid.rows * self.grid.cols), name=f\"Local_State{self.id}\") #Input: local state\n",
    "        prev_action = tf.keras.layers.Input(batch_shape=(1, None, len(Actions)), name=f\"Prev_Action{self.id}\") #Input: previous action\n",
    "        y = tf.keras.layers.Reshape((-1, (self.grid.num_agents+2) * self.grid.rows * self.grid.cols))(local_state)\n",
    "        y = tf.keras.layers.Concatenate(axis=-1)([y, prev_action])\n",
    "        y = tf.keras.layers.Dense(64, activation=\"relu\")(y)\n",
    "        y = tf.keras.layers.GRU(64, stateful=False)(y)\n",
    "        y = tf.keras.layers.Dense(len(Actions))(y) #Output: q value of actions\n",
    "\n",
    "        model = tf.keras.Model((local_state, prev_action), y) # outputs hidden state tensor->pass back in as input return_state=true\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=tf.keras.losses.Huber())\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def step(self):\n",
    "        current_state = self.get_local_state()\n",
    "\n",
    "        self.history[0].append(current_state)\n",
    "        self.history[1].append(self.previous_action.one_hot)\n",
    "        \n",
    "        pred_qvalues = self.local_model((np.array([self.history[0]]), np.array([self.history[1]])))[0].numpy() #placeholder action\n",
    "        pred_max_index = np.argmax(pred_qvalues)\n",
    "\n",
    "        if random.random() < self.epsilon:\n",
    "           action = random.choice(list(Actions))\n",
    "        else:\n",
    "            action = Actions(pred_max_index)\n",
    "            \n",
    "        self.take_action(action)\n",
    "        self.previous_action = action\n",
    "        future_state = self.get_local_state()\n",
    "        \n",
    "        reward = self.get_reward()\n",
    "        \n",
    "        future_qvalues  = self.local_model((np.array([self.history[0]+[future_state]]), np.array([self.history[1]+[action.one_hot]])))[0].numpy()\n",
    "        future_max_index = np.argmax(future_qvalues)\n",
    "\n",
    "        target_qvalue = self.get_correct_qvalue(pred_qvalues[pred_max_index], reward, future_qvalues[future_max_index])\n",
    "        target_qvalues = pred_qvalues.copy()\n",
    "        target_qvalues[pred_max_index] = target_qvalue\n",
    "\n",
    "        self.grid.q_values[self.id] = target_qvalue\n",
    "\n",
    "        self.local_model.fit((np.array([self.history[0]]), np.array([self.history[1]])), np.array([target_qvalues]), verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49cf496f-563b-47d1-8648-9cfdc2c49efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MixingLayer(tf.keras.layers.Layer):\n",
    "#     def __init__(self, grid, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.grid = grid\n",
    "        \n",
    "#         self.hyper_w1 = tf.keras.layers.Dense(grid.num_agents*64, use_bias=False) \n",
    "#         self.hyper_b1 = tf.keras.layers.Dense(64, use_bias=False)\n",
    "        \n",
    "#         self.hyper_w2 = tf.keras.layers.Dense(64, use_bias=False)\n",
    "#         self.hyper_b2 = tf.keras.layers.Dense(64, use_bias=False)\n",
    "#         self.hyper_b2_final = tf.keras.layers.Dense(1, use_bias=False)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         # q_values = tf.transpose(tf.reshape(inputs[0], (1, self.grid.num_agents, -1)), (0, 2, 1))\n",
    "#         q_values = tf.transpose(tf.reshape(inputs[0], (1, self.grid.num_agents, -1)), (0, 1, 2))\n",
    "\n",
    "#         state_dim = inputs[0].shape[-1]\n",
    "#         global_state = tf.reshape(inputs[1], (1, -1))\n",
    "\n",
    "#         w1 = self.hyper_w1(global_state) # take in global state to produce 1st layer weights\n",
    "#         w1 = tf.math.abs(w1) # take absolute value\n",
    "#         w1 = tf.reshape(w1, (1, grid.num_agents, 64))\n",
    "#         b1 = self.hyper_b1(global_state) # add the bias\n",
    "#         print(w1.shape, b1.shape, q_values.shape)\n",
    "#         output_w1 = tf.keras.activations.elu(tf.matmul(q_values, w1) + b1)\n",
    "#         print(\"layer 1\", output_w1.shape)\n",
    "        \n",
    "#         w2 = self.hyper_w2(global_state)\n",
    "#         w2 = tf.math.abs(w2)\n",
    "#         b2 = tf.keras.activations.relu(self.hyper_b2(global_state))\n",
    "#         b2 = self.hyper_b2_final(b2)\n",
    "\n",
    "#         print(\"layer1 reshape\", output_w1.shape)\n",
    "#         print(\"layer 2\", w2.shape)\n",
    "        \n",
    "#         joint_q = tf.matmul(output_w1, w2, transpose_b=True) + b2\n",
    "#         print(\"joint q\", joint_q.shape)\n",
    "#         joint_q = tf.reshape(joint_q, (1, -1))\n",
    "#         print(\"joint q output\", joint_q.shape)\n",
    "#         return joint_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "78a97565-5506-4723-b530-12659ac7a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QMixer(nn.Module):\n",
    "    def __init__(self, n_agents, state_shape, mixing_embed_dim, hyper_embed):\n",
    "        super(QMixer, self).__init__()\n",
    "\n",
    "        # self.args = args\n",
    "        self.n_agents = n_agents\n",
    "        self.state_dim = int(np.prod(state_shape))\n",
    "\n",
    "        self.embed_dim = mixing_embed_dim\n",
    "\n",
    "        # if getattr(\"hypernet_layers\", 1) == 1:\n",
    "        #     self.hyper_w_1 = nn.Linear(self.state_dim, self.embed_dim * self.n_agents)\n",
    "        #     self.hyper_w_final = nn.Linear(self.state_dim, self.embed_dim)\n",
    "        # elif getattr(args,\"hypernet_layers\", 1) == 2:\n",
    "        hypernet_embed = hyper_embed\n",
    "        self.hyper_w_1 = nn.Sequential(nn.Linear(self.state_dim, hypernet_embed),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hypernet_embed, self.embed_dim * self.n_agents))\n",
    "        self.hyper_w_final = nn.Sequential(nn.Linear(self.state_dim, hypernet_embed),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hypernet_embed, self.embed_dim))\n",
    "\n",
    "        # State dependent bias for hidden layer\n",
    "        self.hyper_b_1 = nn.Linear(self.state_dim, self.embed_dim)\n",
    "\n",
    "        # V(s) instead of a bias for the last layers\n",
    "        self.V = nn.Sequential(nn.Linear(self.state_dim, self.embed_dim),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(self.embed_dim, 1))\n",
    "\n",
    "    def forward(self, agent_qs, states):\n",
    "        bs = agent_qs.size(0)\n",
    "        states = states.reshape(-1, self.state_dim)\n",
    "        agent_qs = agent_qs.view(-1, 1, self.n_agents)\n",
    "        # First layer\n",
    "        w1 = th.abs(self.hyper_w_1(states))\n",
    "        b1 = self.hyper_b_1(states)\n",
    "        w1 = w1.view(-1, self.n_agents, self.embed_dim)\n",
    "        b1 = b1.view(-1, 1, self.embed_dim)\n",
    "        hidden = F.elu(th.bmm(agent_qs, w1) + b1)\n",
    "        # Second layer\n",
    "        w_final = th.abs(self.hyper_w_final(states))\n",
    "        w_final = w_final.view(-1, self.embed_dim, 1)\n",
    "        # State-dependent bias\n",
    "        v = self.V(states).view(-1, 1, 1)\n",
    "        # Compute final output\n",
    "        y = th.bmm(hidden, w_final) + v\n",
    "        # Reshape and return\n",
    "        q_tot = y.view(bs, -1, 1)\n",
    "        return q_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7bb4b810-67dc-47e0-9aa4-1cb7ce152718",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_agents = 5\n",
    "agent_qs = torch.Tensor(np.random.normal(size=(1, n_agents)))\n",
    "states = torch.Tensor(np.random.normal(size=(1, 6, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ca7a9874-3c1a-4964-b68d-d350f4df4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer = QMixer(n_agents, (6, 6), 32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1a7a011d-a8ff-4b72-990e-a81849591b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4938]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixer.forward(agent_qs, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "446c24db-a4cc-4471-a8bb-f8d51ab18709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, grid, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.grid = grid\n",
    "        self.state_dim = int(np.prod(np.shape(grid.get_global_state())))\n",
    "        self.embed_dim = 64\n",
    "        \n",
    "        self.hyper_w1 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(self.state_dim),\n",
    "            tf.keras.layers.Dense(self.embed_dim),\n",
    "            tf.keras.layers.Activation(\"relu\"),\n",
    "            tf.keras.layers.Dense(self.embed_dim*self.grid.num_agents)\n",
    "        ])\n",
    "\n",
    "        self.hyper_w2 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(self.state_dim),\n",
    "            tf.keras.layers.Dense(self.embed_dim),\n",
    "            tf.keras.layers.Activation(\"relu\"),\n",
    "            tf.keras.layers.Dense(self.embed_dim)\n",
    "        ])\n",
    "\n",
    "        self.hyper_b1 = tf.keras.layers.Dense(self.embed_dim, input_shape=[self.state_dim])\n",
    "        \n",
    "        self.hyper_b2 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(self.state_dim),\n",
    "            tf.keras.layers.Dense(self.embed_dim),\n",
    "            tf.keras.layers.Activation(\"relu\"),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ]) \n",
    "\n",
    "    ''' def forward(self, agent_qs, states):\n",
    "        bs = agent_qs.size(0)\n",
    "        states = states.reshape(-1, self.state_dim)\n",
    "        \n",
    "        agent_qs = agent_qs.view(-1, 1, self.n_agents)\n",
    "        \n",
    "        # First layer\n",
    "        w1 = th.abs(self.hyper_w_1(states))\n",
    "        b1 = self.hyper_b_1(states)\n",
    "        \n",
    "        w1 = w1.view(-1, self.n_agents, self.embed_dim)\n",
    "        \n",
    "        b1 = b1.view(-1, 1, self.embed_dim)\n",
    "        \n",
    "        hidden = F.elu(th.bmm(agent_qs, w1) + b1)\n",
    "        \n",
    "        # Second layer\n",
    "        w_final = th.abs(self.hyper_w_final(states))\n",
    "        w_final = w_final.view(-1, self.embed_dim, 1)\n",
    "        # State-dependent bias\n",
    "        v = self.V(states).view(-1, 1, 1)\n",
    "        # Compute final output\n",
    "        y = th.bmm(hidden, w_final) + v\n",
    "        # Reshape and return\n",
    "        q_tot = y.view(bs, -1, 1)\n",
    "        return q_tot'''\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # q_values = tf.reshape(inputs[0], (1, self.grid.num_agents, -1)) # 1, 2, 5\n",
    "        q_values = tf.transpose(tf.reshape(inputs[0], (1, self.grid.num_agents, -1)), (2, 0, 1))\n",
    "        global_state = tf.reshape(inputs[1] , (-1, self.state_dim)) # 1, 144\n",
    "\n",
    "        w1 = self.hyper_w1(global_state)\n",
    "        w1 = tf.math.abs(w1) \n",
    "        w1 = tf.reshape(w1, (1, grid.num_agents, 64)) \n",
    "\n",
    "        b1 = self.hyper_b1(global_state)\n",
    "        \n",
    "        b1 = tf.reshape(b1, (-1, 1, 64))\n",
    "        print(w1.shape, b1.shape)\n",
    "\n",
    "        layer1 = tf.matmul(q_values, w1)\n",
    "\n",
    "        # layer1 = tf.keras.activations.elu(tf.matmul(q_values, w1) + b1)\n",
    "\n",
    "        print(layer1.shape)\n",
    "        \n",
    "        # w2 = self.hyper_w2(global_state)\n",
    "        # w2 = tf.math.abs(w2)\n",
    "        # b2 = tf.keras.activations.relu(self.hyper_b2(global_state))\n",
    "        # b2 = self.hyper_b2_final(b2)\n",
    "\n",
    "        # joint_q = tf.matmul(output_w1, w2, transpose_b=True) + b2\n",
    "        # joint_q = tf.reshape(joint_q, (1, -1))\n",
    "        # return joint_q\n",
    "        return 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "abf9b535-642f-4401-ad2f-0f770cb5d55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 64) (1, 1, 64)\n",
      "(5, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "rows = 6\n",
    "cols = 6\n",
    "num_agents = 2\n",
    "\n",
    "grid = GridEnv(rows, cols, num_agents)\n",
    "grid.populate_grid()\n",
    "qmix = grid.qmix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "456a646b-2088-4f26-99e5-2e255e4d0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_state = grid.get_global_state()\n",
    "agent_states = []\n",
    "for agent in grid.agent_list:\n",
    "    agent_states.append(np.array([[agent.get_local_state()]]))\n",
    "    agent_states.append(np.array([[agent.previous_action.one_hot]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7686935c-7e05-4d8b-ab35-e658a9d1934c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 64) (1, 1, 64)\n",
      "(5, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "q_values, q_total = qmix((agent_states, global_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754adb3f-902f-4d5f-ba16-3c29f9c0e96b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

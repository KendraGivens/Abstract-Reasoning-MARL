{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24390d31-a22f-4132-bf14-f8e97f445816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from enum import Enum, auto\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d96c93ab-e6ab-4295-9ee8-d51503fc7df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get config of qmix algorithim \n",
    "with open('qmix.yaml', 'r') as f:\n",
    "    qmix_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "# get config of environment\n",
    "with open('env.yaml', 'r') as f:\n",
    "    env_config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ada5f73-4d9d-48c9-b19a-42b1e6d16ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action_selector': 'epsilon_greedy',\n",
       " 'epsilon_start': 1.0,\n",
       " 'epsilon_finish': 0.05,\n",
       " 'epsilon_anneal_time': 50000,\n",
       " 'runner': 'episode',\n",
       " 'buffer_size': 5000,\n",
       " 'target_update_interval': 200,\n",
       " 'agent_output_type': 'q',\n",
       " 'learner': 'q_learner',\n",
       " 'double_q': True,\n",
       " 'mixer': 'qmix',\n",
       " 'mixing_embed_dim': 32,\n",
       " 'hypernet_layers': 2,\n",
       " 'hypernet_embed': 64,\n",
       " 'name': 'qmix'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmix_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba561c5e-f4b2-4421-9b24-d813e2a44498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rows': 6, 'cols': 6, 'num_agents': 4, 'name': 'block_problem'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af6faad3-e235-43ea-a349-95babc583c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(Enum):\n",
    "    NO_OP = 0\n",
    "    MOVE_UP = auto()\n",
    "    MOVE_DOWN = auto()\n",
    "    MOVE_LEFT = auto()\n",
    "    MOVE_RIGHT = auto()\n",
    "    \n",
    "    @property\n",
    "    def delta(self):\n",
    "        if self == self.NO_OP:\n",
    "            return (0, 0)\n",
    "        if self == self.MOVE_UP:\n",
    "            return (-1, 0)\n",
    "        if self == self.MOVE_DOWN:\n",
    "            return (1, 0)\n",
    "        if self == self.MOVE_LEFT:\n",
    "            return (0, -1)\n",
    "        if self == self.MOVE_RIGHT:\n",
    "            return (0, 1)\n",
    "\n",
    "    @property \n",
    "    def shape(self):\n",
    "        return len(Actions)\n",
    "\n",
    "    @property \n",
    "    def one_hot(self):\n",
    "        return tf.one_hot(self.value, len(Actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed3dfb32-e203-415f-928b-655d6b92049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridEnv():\n",
    "    def __init__(self, rows, cols, num_agents):\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        \n",
    "        self.num_agents = num_agents\n",
    "        self.agent_list = []\n",
    "        \n",
    "        self.goal = []\n",
    "        self.block = []\n",
    "\n",
    "    def qmix(self):\n",
    "        agent_inputs = [agent.local_model.inputs for agent in self.agent_list]\n",
    "        agent_outputs = [agent.local_model.output for agent in self.agent_list]\n",
    "        global_state = tf.keras.layers.Input(batch_shape=(1, *np.shape(self.get_global_state())))\n",
    "\n",
    "        q_values = tf.keras.layers.Concatenate()(agent_outputs)\n",
    "        y = MixingLayer(grid)((q_values, global_state))\n",
    "        qmix = tf.keras.Model((agent_inputs, global_state), (agent_outputs, y))\n",
    "        qmix.compile(run_eagerly=True)\n",
    "        \n",
    "        return qmix\n",
    "\n",
    "    def populate_grid(self):\n",
    "        positions = np.random.choice(self.rows*self.cols, self.num_agents+2, replace=False)\n",
    "\n",
    "        self.goal = (positions[0]//self.cols, positions[0]%self.cols)\n",
    "        self.block = (positions[1]//self.cols, positions[1]%self.cols)\n",
    "\n",
    "        for i in range(self.num_agents):\n",
    "            agent = Agent(self, i)\n",
    "            agent.position = (positions[i+2]//self.cols, positions[i+2]%self.cols)\n",
    "            self.agent_list.append(agent)\n",
    "\n",
    "    def get_global_state(self):\n",
    "        return tf.one_hot([p[0]*self.cols+p[1] for p in (self.goal, self.block, *[a.position for a in self.agent_list])], self.rows*self.cols)\n",
    "    \n",
    "    def vizualize_grid(self): \n",
    "        grid = [list(\".\"*self.cols) for _ in range(self.rows)]\n",
    "\n",
    "        grid[self.goal[0]][self.goal[1]] = \"G\"\n",
    "        grid[self.block[0]][self.block[1]]= \"B\"\n",
    "\n",
    "        for i, agent in enumerate(self.agent_list):\n",
    "            grid[agent.position[0]][agent.position[1]] = str(i)\n",
    "\n",
    "        return '\\n'.join([' '.join(row) for row in grid])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.vizualize_grid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a354d3ab-cc86-44ca-a898-d4fc27f56f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, grid, id):\n",
    "        self.grid = grid\n",
    "\n",
    "        self.id = id\n",
    "        self.position = [0, 0]\n",
    "        self.epsilon = 0.1\n",
    "        self.gamma = 0.1\n",
    "        self.alpha = 0.1\n",
    "        \n",
    "        self.local_model = self._build_local_model() \n",
    "\n",
    "        self.history = ([], [])\n",
    "        self.previous_action = Actions.NO_OP\n",
    "\n",
    "    def get_local_state(self):\n",
    "        return self.grid.get_global_state()\n",
    "\n",
    "    def take_action(self, action):\n",
    "        future_position = self.position\n",
    "        future_position += np.array(action.delta)\n",
    "        future_position %= [self.grid.rows, self.grid.cols]\n",
    "\n",
    "        if list(future_position) not in [a.position for a in self.grid.agent_list]:\n",
    "            if list(future_position) == self.grid.block:\n",
    "                self.grid.block += np.array(action.delta)\n",
    "                self.grid.block %= [self.grid.rows, self.grid.cols]\n",
    "            else:\n",
    "                self.position = future_position\n",
    "            \n",
    "    def get_reward(self):\n",
    "        if self.grid.block == self.grid.goal:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def get_correct_qvalue(self, pred_max_value, reward, current_max_value):\n",
    "        q_value = pred_max_value + self.alpha * (reward + self.gamma * current_max_value - pred_max_value)\n",
    "        return q_value\n",
    "                \n",
    "    def _build_local_model(self):\n",
    "        local_state = tf.keras.layers.Input(batch_shape=(1, None, self.grid.num_agents+2, self.grid.rows * self.grid.cols), name=f\"Local_State{self.id}\") #Input: local state\n",
    "        prev_action = tf.keras.layers.Input(batch_shape=(1, None, len(Actions)), name=f\"Prev_Action{self.id}\") #Input: previous action\n",
    "        y = tf.keras.layers.Reshape((-1, (self.grid.num_agents+2) * self.grid.rows * self.grid.cols))(local_state)\n",
    "        y = tf.keras.layers.Concatenate(axis=-1)([y, prev_action])\n",
    "        y = tf.keras.layers.Dense(64, activation=\"relu\")(y)\n",
    "        y = tf.keras.layers.GRU(64, stateful=False)(y)\n",
    "        y = tf.keras.layers.Dense(len(Actions))(y) #Output: q value of actions\n",
    "\n",
    "        model = tf.keras.Model((local_state, prev_action), y) # outputs hidden state tensor->pass back in as input return_state=true\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=tf.keras.losses.Huber())\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def step(self):\n",
    "        current_state = self.get_local_state()\n",
    "\n",
    "        self.history[0].append(current_state)\n",
    "        self.history[1].append(self.previous_action.one_hot)\n",
    "        \n",
    "        pred_qvalues = self.local_model((np.array([self.history[0]]), np.array([self.history[1]])))[0].numpy() #placeholder action\n",
    "        pred_max_index = np.argmax(pred_qvalues)\n",
    "\n",
    "        if random.random() < self.epsilon:\n",
    "           action = random.choice(list(Actions))\n",
    "        else:\n",
    "            action = Actions(pred_max_index)\n",
    "            \n",
    "        self.take_action(action)\n",
    "        self.previous_action = action\n",
    "        future_state = self.get_local_state()\n",
    "        \n",
    "        reward = self.get_reward()\n",
    "        \n",
    "        future_qvalues  = self.local_model((np.array([self.history[0]+[future_state]]), np.array([self.history[1]+[action.one_hot]])))[0].numpy()\n",
    "        future_max_index = np.argmax(future_qvalues)\n",
    "\n",
    "        target_qvalue = self.get_correct_qvalue(pred_qvalues[pred_max_index], reward, future_qvalues[future_max_index])\n",
    "        target_qvalues = pred_qvalues.copy()\n",
    "        target_qvalues[pred_max_index] = target_qvalue\n",
    "\n",
    "        self.grid.q_values[self.id] = target_qvalue\n",
    "\n",
    "        self.local_model.fit((np.array([self.history[0]]), np.array([self.history[1]])), np.array([target_qvalues]), verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49cf496f-563b-47d1-8648-9cfdc2c49efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MixingLayer(tf.keras.layers.Layer):\n",
    "#     def __init__(self, grid, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.grid = grid\n",
    "        \n",
    "#         self.hyper_w1 = tf.keras.layers.Dense(grid.num_agents*64, use_bias=False) \n",
    "#         self.hyper_b1 = tf.keras.layers.Dense(64, use_bias=False)\n",
    "        \n",
    "#         self.hyper_w2 = tf.keras.layers.Dense(64, use_bias=False)\n",
    "#         self.hyper_b2 = tf.keras.layers.Dense(64, use_bias=False)\n",
    "#         self.hyper_b2_final = tf.keras.layers.Dense(1, use_bias=False)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         # q_values = tf.transpose(tf.reshape(inputs[0], (1, self.grid.num_agents, -1)), (0, 2, 1))\n",
    "#         q_values = tf.transpose(tf.reshape(inputs[0], (1, self.grid.num_agents, -1)), (0, 1, 2))\n",
    "\n",
    "#         state_dim = inputs[0].shape[-1]\n",
    "#         global_state = tf.reshape(inputs[1], (1, -1))\n",
    "\n",
    "#         w1 = self.hyper_w1(global_state) # take in global state to produce 1st layer weights\n",
    "#         w1 = tf.math.abs(w1) # take absolute value\n",
    "#         w1 = tf.reshape(w1, (1, grid.num_agents, 64))\n",
    "#         b1 = self.hyper_b1(global_state) # add the bias\n",
    "#         print(w1.shape, b1.shape, q_values.shape)\n",
    "#         output_w1 = tf.keras.activations.elu(tf.matmul(q_values, w1) + b1)\n",
    "#         print(\"layer 1\", output_w1.shape)\n",
    "        \n",
    "#         w2 = self.hyper_w2(global_state)\n",
    "#         w2 = tf.math.abs(w2)\n",
    "#         b2 = tf.keras.activations.relu(self.hyper_b2(global_state))\n",
    "#         b2 = self.hyper_b2_final(b2)\n",
    "\n",
    "#         print(\"layer1 reshape\", output_w1.shape)\n",
    "#         print(\"layer 2\", w2.shape)\n",
    "        \n",
    "#         joint_q = tf.matmul(output_w1, w2, transpose_b=True) + b2\n",
    "#         print(\"joint q\", joint_q.shape)\n",
    "#         joint_q = tf.reshape(joint_q, (1, -1))\n",
    "#         print(\"joint q output\", joint_q.shape)\n",
    "#         return joint_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a97565-5506-4723-b530-12659ac7a705",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mQMixer\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_agents, state_shape, mixing_embed_dim, hyper_embed):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(QMixer, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class QMixer(nn.Module):\n",
    "    def __init__(self, n_agents, state_shape, mixing_embed_dim, hyper_embed):\n",
    "        super(QMixer, self).__init__()\n",
    "\n",
    "        # self.args = args\n",
    "        self.n_agents = n_agents\n",
    "        self.state_dim = int(np.prod(state_shape))\n",
    "\n",
    "        self.embed_dim = mixing_embed_dim\n",
    "\n",
    "        # if getattr(\"hypernet_layers\", 1) == 1:\n",
    "        #     self.hyper_w_1 = nn.Linear(self.state_dim, self.embed_dim * self.n_agents)\n",
    "        #     self.hyper_w_final = nn.Linear(self.state_dim, self.embed_dim)\n",
    "        # elif getattr(args,\"hypernet_layers\", 1) == 2:\n",
    "        hypernet_embed = hyper_embed\n",
    "        self.hyper_w_1 = nn.Sequential(nn.Linear(self.state_dim, hypernet_embed),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hypernet_embed, self.embed_dim * self.n_agents))\n",
    "        self.hyper_w_final = nn.Sequential(nn.Linear(self.state_dim, hypernet_embed),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Linear(hypernet_embed, self.embed_dim))\n",
    "        # elif getattr(args, \"hypernet_layers\", 1) > 2:\n",
    "        #     raise Exception(\"Sorry >2 hypernet layers is not implemented!\")\n",
    "        # else:\n",
    "        #     raise Exception(\"Error setting number of hypernet layers.\")\n",
    "\n",
    "        # State dependent bias for hidden layer\n",
    "        self.hyper_b_1 = nn.Linear(self.state_dim, self.embed_dim)\n",
    "\n",
    "        # V(s) instead of a bias for the last layers\n",
    "        self.V = nn.Sequential(nn.Linear(self.state_dim, self.embed_dim),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(self.embed_dim, 1))\n",
    "\n",
    "    def forward(self, agent_qs, states):\n",
    "        bs = agent_qs.size(0)\n",
    "        states = states.reshape(-1, self.state_dim)\n",
    "        agent_qs = agent_qs.view(-1, 1, self.n_agents)\n",
    "        # First layer\n",
    "        w1 = th.abs(self.hyper_w_1(states))\n",
    "        b1 = self.hyper_b_1(states)\n",
    "        w1 = w1.view(-1, self.n_agents, self.embed_dim)\n",
    "        b1 = b1.view(-1, 1, self.embed_dim)\n",
    "        print(w1.shape, b1.shape)\n",
    "        hidden = F.elu(th.bmm(agent_qs, w1) + b1)\n",
    "        # Second layer\n",
    "        w_final = th.abs(self.hyper_w_final(states))\n",
    "        w_final = w_final.view(-1, self.embed_dim, 1)\n",
    "        # State-dependent bias\n",
    "        v = self.V(states).view(-1, 1, 1)\n",
    "        # Compute final output\n",
    "        y = th.bmm(hidden, w_final) + v\n",
    "        # Reshape and return\n",
    "        q_tot = y.view(bs, -1, 1)\n",
    "        return q_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb4b810-67dc-47e0-9aa4-1cb7ce152718",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_agents = 2\n",
    "agent_qs = torch.Tensor(np.random.normal(size=(1, n_agents)))\n",
    "states = torch.Tensor(np.random.normal(size=(1, 6, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a9874-3c1a-4964-b68d-d350f4df4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer = QMixer(2, (6, 6), 32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a011d-a8ff-4b72-990e-a81849591b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.forward(agent_qs, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2d54a-53a4-4c24-abea-c594386a5528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96adbc03-e38a-493e-8e26-24c826760e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.get_global_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0ab801-10da-421c-adf2-312590550525",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_state = torch.Tensor(grid.get_global_state().numpy())\n",
    "state_dim = np.prod(global_state.numpy().shape)\n",
    "state_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8620b250-8cb0-4355-ba0b-4ab57b6837c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_agents = grid.num_agents\n",
    "n_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25631b3-b03b-4471-800f-6f7208815f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64\n",
    "hypernet_embed = 2*embed_dim\n",
    "\n",
    "hyper_w1 = nn.Sequential(\n",
    "    nn.Linear(state_dim, hypernet_embed),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hypernet_embed, embed_dim * n_agents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679fc34-ba29-4c31-9ac4-ad8f05e8a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_qs = torch.Tensor(np.random.normal(size=(5, 1, n_agents)))\n",
    "agent_qs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccfa6ad-c047-4741-bc56-52a726ecda18",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = global_state.view((-1, state_dim))\n",
    "states.shape\n",
    "states = torch.flatten(states).view((1, -1))\n",
    "states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11653e3c-33b5-4e1e-8dca-39c885c8883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.abs(hyper_w1(states))\n",
    "w1 = w1.view(-1, n_agents, embed_dim)\n",
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8c0b40-38bf-4b46-9b18-e32ded5a0123",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mbmm(w1, agent_qs\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.bmm(w1, agent_qs.transpose(1, 0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "446c24db-a4cc-4471-a8bb-f8d51ab18709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, grid, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.grid = grid\n",
    "        self.state_dim = int(np.prod(np.shape(grid.get_global_state())))\n",
    "        self.embed_dim = 64\n",
    "        \n",
    "        self.hyper_w1 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(self.state_dim),\n",
    "            tf.keras.layers.Dense(self.embed_dim),\n",
    "            tf.keras.layers.Activation(\"relu\"),\n",
    "            tf.keras.layers.Dense(self.embed_dim*self.grid.num_agents)\n",
    "        ])\n",
    "\n",
    "        self.hyper_w2 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(self.state_dim),\n",
    "            tf.keras.layers.Dense(self.embed_dim),\n",
    "            tf.keras.layers.Activation(\"relu\"),\n",
    "            tf.keras.layers.Dense(self.embed_dim)\n",
    "        ])\n",
    "\n",
    "        self.hyper_b1 = tf.keras.layers.Dense(self.embed_dim, input_shape=[self.state_dim])\n",
    "        \n",
    "        self.hyper_b2 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(self.state_dim),\n",
    "            tf.keras.layers.Dense(self.embed_dim),\n",
    "            tf.keras.layers.Activation(\"relu\"),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ]) \n",
    "\n",
    "    ''' def forward(self, agent_qs, states):\n",
    "        bs = agent_qs.size(0)\n",
    "        states = states.reshape(-1, self.state_dim)\n",
    "        \n",
    "        agent_qs = agent_qs.view(-1, 1, self.n_agents)\n",
    "        \n",
    "        # First layer\n",
    "        w1 = th.abs(self.hyper_w_1(states))\n",
    "        b1 = self.hyper_b_1(states)\n",
    "        \n",
    "        w1 = w1.view(-1, self.n_agents, self.embed_dim)\n",
    "        \n",
    "        b1 = b1.view(-1, 1, self.embed_dim)\n",
    "        \n",
    "        hidden = F.elu(th.bmm(agent_qs, w1) + b1)\n",
    "        \n",
    "        # Second layer\n",
    "        w_final = th.abs(self.hyper_w_final(states))\n",
    "        w_final = w_final.view(-1, self.embed_dim, 1)\n",
    "        # State-dependent bias\n",
    "        v = self.V(states).view(-1, 1, 1)\n",
    "        # Compute final output\n",
    "        y = th.bmm(hidden, w_final) + v\n",
    "        # Reshape and return\n",
    "        q_tot = y.view(bs, -1, 1)\n",
    "        return q_tot'''\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # q_values = tf.reshape(inputs[0], (1, self.grid.num_agents, -1)) # 1, 2, 5\n",
    "        q_values = tf.transpose(tf.reshape(inputs[0], (1, self.grid.num_agents, -1)), (2, 0, 1))\n",
    "        global_state = tf.reshape(inputs[1] , (-1, self.state_dim)) # 1, 144\n",
    "\n",
    "        w1 = self.hyper_w1(global_state)\n",
    "        w1 = tf.math.abs(w1) \n",
    "        w1 = tf.reshape(w1, (1, grid.num_agents, 64)) \n",
    "\n",
    "        b1 = self.hyper_b1(global_state)\n",
    "        \n",
    "        b1 = tf.reshape(b1, (-1, 1, 64))\n",
    "        print(w1.shape, b1.shape)\n",
    "\n",
    "        layer1 = tf.matmul(q_values, w1)\n",
    "\n",
    "        # layer1 = tf.keras.activations.elu(tf.matmul(q_values, w1) + b1)\n",
    "\n",
    "        print(layer1.shape)\n",
    "        \n",
    "        # w2 = self.hyper_w2(global_state)\n",
    "        # w2 = tf.math.abs(w2)\n",
    "        # b2 = tf.keras.activations.relu(self.hyper_b2(global_state))\n",
    "        # b2 = self.hyper_b2_final(b2)\n",
    "\n",
    "        # joint_q = tf.matmul(output_w1, w2, transpose_b=True) + b2\n",
    "        # joint_q = tf.reshape(joint_q, (1, -1))\n",
    "        # return joint_q\n",
    "        return 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abf9b535-642f-4401-ad2f-0f770cb5d55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 64) (1, 1, 64)\n",
      "(5, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "rows = 6\n",
    "cols = 6\n",
    "num_agents = 2\n",
    "\n",
    "grid = GridEnv(rows, cols, num_agents)\n",
    "grid.populate_grid()\n",
    "qmix = grid.qmix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "456a646b-2088-4f26-99e5-2e255e4d0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_state = grid.get_global_state()\n",
    "agent_states = []\n",
    "for agent in grid.agent_list:\n",
    "    agent_states.append(np.array([[agent.get_local_state()]]))\n",
    "    agent_states.append(np.array([[agent.previous_action.one_hot]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7686935c-7e05-4d8b-ab35-e658a9d1934c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 64) (1, 1, 64)\n",
      "(5, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "q_values, q_total = qmix((agent_states, global_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c12bfd3-9c43-45e7-aa7a-8bedfdd5bd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.00277368,  0.05317054,  0.17464086,  0.02114644,  0.13932592]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       " array([[-0.05265313,  0.04974331,  0.04907609, -0.02351041, -0.03261544]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d800d75e-0c4f-402b-a82c-2ac8e9ce2269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55858e8-5a70-4509-aa7d-1ba1d899a702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd094984-8240-44d8-936a-f89c9b491bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
